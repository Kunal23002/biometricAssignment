{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CS 228 - Assignment 2: Clean-Label Data Poisoning Attack on CIFAR-10\n",
        "\n",
        "This notebook implements a clean-label poisoning attack on CIFAR-10 dataset, extending the two-class version to a multiclass version.\n",
        "\n",
        "## Overview\n",
        "- **Data Preparation**: Select 4 classes from CIFAR-10, prepare target and base images\n",
        "- **Model Architecture**: Build a small CNN for CIFAR-10 classification\n",
        "- **Initial Training**: Train on clean data and verify baseline performance\n",
        "- **Poison Generation**: Implement iterative poisoning algorithm (Poison Frogs style)\n",
        "- **Retraining & Evaluation**: Retrain with poisons and evaluate attack success\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (run this in Colab)\n",
        "%pip install torch torchvision matplotlib numpy tqdm pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import copy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Preparation\n",
        "\n",
        "Select 4 classes from CIFAR-10, prepare training data, and set aside target/base images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CIFAR-10 class names\n",
        "CIFAR10_CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
        "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Configuration\n",
        "NUM_CLASSES = 4\n",
        "IMAGES_PER_CLASS = 400  # Adjust based on system capacity (200-500)\n",
        "NUM_TARGETS = 10\n",
        "NUM_POISONS = 10\n",
        "\n",
        "# Select 4 classes: we'll use classes 0, 1, 2, 3 (airplane, automobile, bird, cat)\n",
        "SELECTED_CLASSES = [0, 1, 2, 3]\n",
        "TARGET_CLASS = 0  # Class T (airplane)\n",
        "BASE_CLASS = 1    # Class B (automobile)\n",
        "\n",
        "print(f\"Selected classes: {[CIFAR10_CLASSES[i] for i in SELECTED_CLASSES]}\")\n",
        "print(f\"Target class (T): {CIFAR10_CLASSES[TARGET_CLASS]}\")\n",
        "print(f\"Base class (B): {CIFAR10_CLASSES[BASE_CLASS]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "# Load training and test sets\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
        "                                        download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# Filter data for selected classes\n",
        "def filter_classes(dataset, selected_classes):\n",
        "    \"\"\"Filter dataset to only include selected classes\"\"\"\n",
        "    indices = []\n",
        "    for idx, (_, label) in enumerate(dataset):\n",
        "        if label in selected_classes:\n",
        "            indices.append(idx)\n",
        "    return indices\n",
        "\n",
        "train_indices = filter_classes(trainset, SELECTED_CLASSES)\n",
        "test_indices = filter_classes(testset, SELECTED_CLASSES)\n",
        "\n",
        "print(f\"Total training samples for selected classes: {len(train_indices)}\")\n",
        "print(f\"Total test samples for selected classes: {len(test_indices)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample images per class for training\n",
        "def sample_by_class(dataset, indices, class_label, num_samples):\n",
        "    \"\"\"Sample a specific number of images for a given class\"\"\"\n",
        "    class_indices = []\n",
        "    for idx in indices:\n",
        "        _, label = dataset[idx]\n",
        "        if label == class_label:\n",
        "            class_indices.append(idx)\n",
        "    return np.random.choice(class_indices, size=min(num_samples, len(class_indices)), replace=False)\n",
        "\n",
        "# Sample training data\n",
        "selected_train_indices = []\n",
        "for class_idx in SELECTED_CLASSES:\n",
        "    class_samples = sample_by_class(trainset, train_indices, class_idx, IMAGES_PER_CLASS)\n",
        "    selected_train_indices.extend(class_samples.tolist())\n",
        "\n",
        "print(f\"Selected {len(selected_train_indices)} training samples\")\n",
        "\n",
        "# Separate target images (class T) and base images (class B)\n",
        "target_indices = []\n",
        "base_indices = []\n",
        "remaining_train_indices = []\n",
        "\n",
        "for idx in selected_train_indices:\n",
        "    _, label = trainset[idx]\n",
        "    if label == TARGET_CLASS:\n",
        "        if len(target_indices) < NUM_TARGETS:\n",
        "            target_indices.append(idx)\n",
        "        else:\n",
        "            remaining_train_indices.append(idx)\n",
        "    elif label == BASE_CLASS:\n",
        "        if len(base_indices) < NUM_POISONS:\n",
        "            base_indices.append(idx)\n",
        "        else:\n",
        "            remaining_train_indices.append(idx)\n",
        "    else:\n",
        "        remaining_train_indices.append(idx)\n",
        "\n",
        "print(f\"Selected {len(target_indices)} target images (class {CIFAR10_CLASSES[TARGET_CLASS]})\")\n",
        "print(f\"Selected {len(base_indices)} base images (class {CIFAR10_CLASSES[BASE_CLASS]})\")\n",
        "print(f\"Remaining training samples: {len(remaining_train_indices)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "clean_train_subset = Subset(trainset, remaining_train_indices)\n",
        "test_subset = Subset(testset, test_indices)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64\n",
        "clean_train_loader = DataLoader(clean_train_subset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Extract target and base images\n",
        "target_images = []\n",
        "target_labels = []\n",
        "for idx in target_indices:\n",
        "    img, label = trainset[idx]\n",
        "    target_images.append(img)\n",
        "    target_labels.append(label)\n",
        "\n",
        "base_images = []\n",
        "base_labels = []\n",
        "for idx in base_indices:\n",
        "    img, label = trainset[idx]\n",
        "    base_images.append(img)\n",
        "    base_labels.append(label)\n",
        "\n",
        "target_images = torch.stack(target_images).to(device)\n",
        "base_images = torch.stack(base_images).to(device)\n",
        "\n",
        "print(f\"Target images shape: {target_images.shape}\")\n",
        "print(f\"Base images shape: {base_images.shape}\")\n",
        "\n",
        "# Visualize some target and base images\n",
        "def denormalize(tensor, mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)):\n",
        "    \"\"\"Denormalize tensor for visualization\"\"\"\n",
        "    for t, m, s in zip(tensor, mean, std):\n",
        "        t.mul_(s).add_(m)\n",
        "    return tensor.clamp_(0, 1)\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "for i in range(5):\n",
        "    # Target images\n",
        "    img = denormalize(target_images[i].cpu().clone())\n",
        "    axes[0, i].imshow(img.permute(1, 2, 0))\n",
        "    axes[0, i].set_title(f'Target {i}')\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # Base images\n",
        "    img = denormalize(base_images[i].cpu().clone())\n",
        "    axes[1, i].imshow(img.permute(1, 2, 0))\n",
        "    axes[1, i].set_title(f'Base {i}')\n",
        "    axes[1, i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Architecture\n",
        "\n",
        "Build a small CNN suitable for CIFAR-10 classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SmallCNN(nn.Module):\n",
        "    \"\"\"Small CNN for CIFAR-10 classification\"\"\"\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(SmallCNN, self).__init__()\n",
        "        # First convolutional block\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Second convolutional block\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Conv block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        \n",
        "        # Conv block 2\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # FC layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def get_features(self, x):\n",
        "        \"\"\"Extract features from the model (before final FC layer)\"\"\"\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "# Create model\n",
        "model = SmallCNN(num_classes=NUM_CLASSES).to(device)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initial Training (20 points)\n",
        "\n",
        "Train the CNN on clean training data (excluding targets). Verify that it correctly classifies validation set and target images before poisoning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, num_epochs=20, lr=0.001):\n",
        "    \"\"\"Train the model on clean data\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "        \n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "    \n",
        "    return train_losses\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    \"\"\"Evaluate model accuracy\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    class_correct = [0] * NUM_CLASSES\n",
        "    class_total = [0] * NUM_CLASSES\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "            \n",
        "            for i in range(target.size(0)):\n",
        "                label = target[i].item()\n",
        "                class_correct[label] += (predicted[i] == label).item()\n",
        "                class_total[label] += 1\n",
        "    \n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Overall Test Accuracy: {accuracy:.2f}%')\n",
        "    \n",
        "    for i in range(NUM_CLASSES):\n",
        "        if class_total[i] > 0:\n",
        "            class_acc = 100 * class_correct[i] / class_total[i]\n",
        "            print(f'Class {CIFAR10_CLASSES[SELECTED_CLASSES[i]]} Accuracy: {class_acc:.2f}%')\n",
        "    \n",
        "    return accuracy, class_correct, class_total\n",
        "\n",
        "def predict_images(model, images):\n",
        "    \"\"\"Predict labels for a batch of images\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "    \n",
        "    return predicted.cpu().numpy(), probs.cpu().numpy()\n",
        "\n",
        "# Train initial model\n",
        "print(\"=\" * 60)\n",
        "print(\"3. INITIAL TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nTraining initial model on clean data...\")\n",
        "train_losses = train_model(model, clean_train_loader, num_epochs=20)\n",
        "\n",
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss (Clean Data)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "baseline_accuracy, baseline_class_correct, baseline_class_total = evaluate_model(model, test_loader)\n",
        "\n",
        "# Verify target images are correctly classified before poisoning\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Verifying target images (before poisoning):\")\n",
        "print(\"=\" * 60)\n",
        "target_predictions, target_probs = predict_images(model, target_images)\n",
        "target_labels_np = np.array([TARGET_CLASS] * NUM_TARGETS)\n",
        "\n",
        "correct_targets = 0\n",
        "for i in range(NUM_TARGETS):\n",
        "    pred_class = target_predictions[i]\n",
        "    true_class = TARGET_CLASS\n",
        "    is_correct = (pred_class == true_class)\n",
        "    correct_targets += is_correct\n",
        "    print(f\"Target {i}: Predicted={CIFAR10_CLASSES[SELECTED_CLASSES[pred_class]]} \"\n",
        "          f\"(True={CIFAR10_CLASSES[SELECTED_CLASSES[true_class]]}) \"\n",
        "          f\"{'✓' if is_correct else '✗'}\")\n",
        "\n",
        "print(f\"\\nTarget classification accuracy: {100 * correct_targets / NUM_TARGETS:.1f}%\")\n",
        "print(f\"All targets should be correctly classified as {CIFAR10_CLASSES[SELECTED_CLASSES[TARGET_CLASS]]}\")\n",
        "\n",
        "# Store baseline metrics\n",
        "baseline_metrics = {\n",
        "    'test_accuracy': baseline_accuracy,\n",
        "    'target_accuracy': 100 * correct_targets / NUM_TARGETS,\n",
        "    'class_correct': baseline_class_correct,\n",
        "    'class_total': baseline_class_total\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Poison Generation (20 points)\n",
        "\n",
        "Implement the iterative poisoning algorithm (Poison Frogs style) for each poison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_poison(model, base_image, target_image, num_iterations=150, \n",
        "                     lr_forward=0.1, lr_backward=0.01, lambda_backward=0.1):\n",
        "    \"\"\"\n",
        "    Generate a poison image using iterative optimization (Poison Frogs algorithm)\n",
        "    \n",
        "    Args:\n",
        "        model: Trained model (frozen)\n",
        "        base_image: Base image (class B) - shape: (3, 32, 32)\n",
        "        target_image: Target image (class T) - shape: (3, 32, 32)\n",
        "        num_iterations: Number of optimization iterations\n",
        "        lr_forward: Learning rate for forward step (minimize |f(x) - f(t)|^2)\n",
        "        lr_backward: Learning rate for backward step (stay close to base)\n",
        "        lambda_backward: Weight for backward step loss\n",
        "    \n",
        "    Returns:\n",
        "        poison: Generated poison image\n",
        "        history: List of (iteration, poison, feature_distance) tuples\n",
        "    \"\"\"\n",
        "    # Initialize poison as base image (requires gradient)\n",
        "    poison = base_image.clone().detach().requires_grad_(True)\n",
        "    \n",
        "    # Freeze model parameters\n",
        "    model.eval()\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    # Get target features\n",
        "    with torch.no_grad():\n",
        "        target_features = model.get_features(target_image.unsqueeze(0))\n",
        "    \n",
        "    history = []\n",
        "    \n",
        "    for iteration in range(num_iterations):\n",
        "        # Forward step: minimize |f(x) - f(t)|^2\n",
        "        poison_features = model.get_features(poison.unsqueeze(0))\n",
        "        forward_loss = torch.sum((poison_features - target_features) ** 2)\n",
        "        \n",
        "        # Backward step: keep poison close to base image (Frobenius norm)\n",
        "        backward_loss = torch.sum((poison - base_image) ** 2)\n",
        "        \n",
        "        # Total loss\n",
        "        total_loss = forward_loss + lambda_backward * backward_loss\n",
        "        \n",
        "        # Compute gradient\n",
        "        total_loss.backward()\n",
        "        \n",
        "        # Update poison (gradient descent)\n",
        "        with torch.no_grad():\n",
        "            # Forward step update\n",
        "            poison.data -= lr_forward * poison.grad.data\n",
        "            \n",
        "            # Backward step update (additional constraint)\n",
        "            poison.data -= lr_backward * lambda_backward * (poison.data - base_image.data)\n",
        "            \n",
        "            # Clip to valid image range [0, 1] (after denormalization)\n",
        "            # Since images are normalized, we need to clip in normalized space\n",
        "            # For CIFAR-10 normalization: mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)\n",
        "            # Valid range in normalized space: approximately [-2.5, 2.5]\n",
        "            poison.data = torch.clamp(poison.data, -2.5, 2.5)\n",
        "        \n",
        "        poison.grad.zero_()\n",
        "        \n",
        "        # Record history every 20 iterations\n",
        "        if (iteration + 1) % 20 == 0 or iteration == 0:\n",
        "            with torch.no_grad():\n",
        "                current_features = model.get_features(poison.unsqueeze(0))\n",
        "                feature_distance = torch.norm(current_features - target_features).item()\n",
        "            history.append((iteration + 1, poison.clone().detach(), feature_distance))\n",
        "    \n",
        "    return poison.detach(), history\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"4. POISON GENERATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nGenerating {NUM_POISONS} poison images...\")\n",
        "print(f\"Each poison will be optimized for 150 iterations\")\n",
        "print(f\"Target class: {CIFAR10_CLASSES[SELECTED_CLASSES[TARGET_CLASS]]}\")\n",
        "print(f\"Base class: {CIFAR10_CLASSES[SELECTED_CLASSES[BASE_CLASS]]}\\n\")\n",
        "\n",
        "# Generate poisons for each target-base pair\n",
        "poisons = []\n",
        "poison_histories = []\n",
        "\n",
        "for i in tqdm(range(NUM_POISONS), desc=\"Generating poisons\"):\n",
        "    # Use target i and base i (can also pair differently)\n",
        "    target_idx = i % NUM_TARGETS  # Cycle through targets if needed\n",
        "    base_idx = i\n",
        "    \n",
        "    poison, history = generate_poison(\n",
        "        model, \n",
        "        base_images[base_idx], \n",
        "        target_images[target_idx],\n",
        "        num_iterations=150,\n",
        "        lr_forward=0.1,\n",
        "        lr_backward=0.01,\n",
        "        lambda_backward=0.1\n",
        "    )\n",
        "    \n",
        "    poisons.append(poison)\n",
        "    poison_histories.append(history)\n",
        "\n",
        "poisons = torch.stack(poisons)\n",
        "print(f\"\\nGenerated {len(poisons)} poison images\")\n",
        "print(f\"Poison shape: {poisons.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize poison evolution for a few examples\n",
        "print(\"\\nVisualizing poison evolution...\")\n",
        "num_examples = min(3, NUM_POISONS)\n",
        "\n",
        "fig, axes = plt.subplots(num_examples, len(poison_histories[0]) + 1, figsize=(20, 4 * num_examples))\n",
        "\n",
        "if num_examples == 1:\n",
        "    axes = axes.reshape(1, -1)\n",
        "\n",
        "for i in range(num_examples):\n",
        "    history = poison_histories[i]\n",
        "    \n",
        "    # Show base image\n",
        "    base_img = denormalize(base_images[i].cpu().clone())\n",
        "    axes[i, 0].imshow(base_img.permute(1, 2, 0))\n",
        "    axes[i, 0].set_title(f'Base Image {i}\\n(Initial)')\n",
        "    axes[i, 0].axis('off')\n",
        "    \n",
        "    # Show poison at different iterations\n",
        "    for j, (iter_num, poison_img, feat_dist) in enumerate(history):\n",
        "        poison_vis = denormalize(poison_img.cpu().clone())\n",
        "        axes[i, j + 1].imshow(poison_vis.permute(1, 2, 0))\n",
        "        axes[i, j + 1].set_title(f'Iteration {iter_num}\\nDist: {feat_dist:.2f}')\n",
        "        axes[i, j + 1].axis('off')\n",
        "    \n",
        "    # Show target image in last column\n",
        "    target_img = denormalize(target_images[i % NUM_TARGETS].cpu().clone())\n",
        "    axes[i, -1].imshow(target_img.permute(1, 2, 0))\n",
        "    axes[i, -1].set_title(f'Target Image {i % NUM_TARGETS}\\n(Goal)')\n",
        "    axes[i, -1].axis('off')\n",
        "\n",
        "plt.suptitle('Poison Evolution During Optimization', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot feature distance convergence\n",
        "fig, axes = plt.subplots(1, num_examples, figsize=(5 * num_examples, 4))\n",
        "if num_examples == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i in range(num_examples):\n",
        "    history = poison_histories[i]\n",
        "    iterations = [h[0] for h in history]\n",
        "    distances = [h[2] for h in history]\n",
        "    \n",
        "    axes[i].plot(iterations, distances, marker='o')\n",
        "    axes[i].set_xlabel('Iteration')\n",
        "    axes[i].set_ylabel('Feature Distance |f(x) - f(t)|')\n",
        "    axes[i].set_title(f'Poison {i}: Feature Distance Convergence')\n",
        "    axes[i].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize final poison images\n",
        "print(\"\\nFinal poison images:\")\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "\n",
        "for i in range(min(10, NUM_POISONS)):\n",
        "    row = i // 5\n",
        "    col = i % 5\n",
        "    \n",
        "    # Final poison\n",
        "    poison_img = denormalize(poisons[i].cpu().clone())\n",
        "    axes[row, col].imshow(poison_img.permute(1, 2, 0))\n",
        "    axes[row, col].set_title(f'Poison {i}\\n(Label: {CIFAR10_CLASSES[SELECTED_CLASSES[BASE_CLASS]]})')\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.suptitle('Final Generated Poison Images', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Compare base, poison, and target for a few examples\n",
        "print(\"\\nComparison: Base vs Poison vs Target\")\n",
        "num_comparisons = min(3, NUM_POISONS)\n",
        "fig, axes = plt.subplots(num_comparisons, 3, figsize=(12, 4 * num_comparisons))\n",
        "\n",
        "if num_comparisons == 1:\n",
        "    axes = axes.reshape(1, -1)\n",
        "\n",
        "for i in range(num_comparisons):\n",
        "    # Base\n",
        "    base_img = denormalize(base_images[i].cpu().clone())\n",
        "    axes[i, 0].imshow(base_img.permute(1, 2, 0))\n",
        "    axes[i, 0].set_title(f'Base {i}\\n({CIFAR10_CLASSES[SELECTED_CLASSES[BASE_CLASS]]})')\n",
        "    axes[i, 0].axis('off')\n",
        "    \n",
        "    # Poison\n",
        "    poison_img = denormalize(poisons[i].cpu().clone())\n",
        "    axes[i, 1].imshow(poison_img.permute(1, 2, 0))\n",
        "    axes[i, 1].set_title(f'Poison {i}\\n(Label: {CIFAR10_CLASSES[SELECTED_CLASSES[BASE_CLASS]]})')\n",
        "    axes[i, 1].axis('off')\n",
        "    \n",
        "    # Target\n",
        "    target_img = denormalize(target_images[i % NUM_TARGETS].cpu().clone())\n",
        "    axes[i, 2].imshow(target_img.permute(1, 2, 0))\n",
        "    axes[i, 2].set_title(f'Target {i % NUM_TARGETS}\\n({CIFAR10_CLASSES[SELECTED_CLASSES[TARGET_CLASS]]})')\n",
        "    axes[i, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Retraining and Evaluation (20 points)\n",
        "\n",
        "Insert the final poisons into the training set (with label B) and retrain the CNN from scratch. Evaluate on test set and target images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"5. RETRAINING AND EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create poisoned training set\n",
        "print(\"\\nCreating poisoned training set...\")\n",
        "print(f\"Adding {NUM_POISONS} poison images with label {CIFAR10_CLASSES[SELECTED_CLASSES[BASE_CLASS]]}\")\n",
        "\n",
        "# Get clean training data\n",
        "clean_train_data = []\n",
        "clean_train_labels = []\n",
        "for idx in remaining_train_indices:\n",
        "    img, label = trainset[idx]\n",
        "    clean_train_data.append(img)\n",
        "    clean_train_labels.append(label)\n",
        "\n",
        "# Add poisons with base class label\n",
        "poison_labels = [BASE_CLASS] * NUM_POISONS\n",
        "poisoned_train_data = clean_train_data + [poisons[i].cpu() for i in range(NUM_POISONS)]\n",
        "poisoned_train_labels = clean_train_labels + poison_labels\n",
        "\n",
        "print(f\"Clean training samples: {len(clean_train_data)}\")\n",
        "print(f\"Poison samples: {NUM_POISONS}\")\n",
        "print(f\"Total poisoned training samples: {len(poisoned_train_data)}\")\n",
        "\n",
        "# Create dataset and dataloader\n",
        "poisoned_train_dataset = TensorDataset(\n",
        "    torch.stack(poisoned_train_data),\n",
        "    torch.tensor(poisoned_train_labels)\n",
        ")\n",
        "poisoned_train_loader = DataLoader(poisoned_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create a new model for retraining\n",
        "print(\"\\nInitializing new model for retraining...\")\n",
        "poisoned_model = SmallCNN(num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "# Retrain from scratch\n",
        "print(\"\\nRetraining model on poisoned data...\")\n",
        "poisoned_train_losses = train_model(poisoned_model, poisoned_train_loader, num_epochs=20)\n",
        "\n",
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(poisoned_train_losses, label='Poisoned Training')\n",
        "plt.plot(train_losses, label='Clean Training', linestyle='--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss: Clean vs Poisoned')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Evaluating poisoned model on test set:\")\n",
        "print(\"=\" * 60)\n",
        "poisoned_accuracy, poisoned_class_correct, poisoned_class_total = evaluate_model(poisoned_model, test_loader)\n",
        "\n",
        "# Compare accuracies\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Accuracy Comparison:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Baseline (clean) test accuracy: {baseline_metrics['test_accuracy']:.2f}%\")\n",
        "print(f\"Poisoned test accuracy: {poisoned_accuracy:.2f}%\")\n",
        "print(f\"Difference: {poisoned_accuracy - baseline_metrics['test_accuracy']:.2f}%\")\n",
        "\n",
        "# Per-class accuracy comparison\n",
        "print(\"\\nPer-class accuracy comparison:\")\n",
        "print(f\"{'Class':<15} {'Baseline':<12} {'Poisoned':<12} {'Difference':<12}\")\n",
        "print(\"-\" * 50)\n",
        "for i in range(NUM_CLASSES):\n",
        "    baseline_acc = 100 * baseline_metrics['class_correct'][i] / baseline_metrics['class_total'][i] if baseline_metrics['class_total'][i] > 0 else 0\n",
        "    poisoned_acc = 100 * poisoned_class_correct[i] / poisoned_class_total[i] if poisoned_class_total[i] > 0 else 0\n",
        "    diff = poisoned_acc - baseline_acc\n",
        "    print(f\"{CIFAR10_CLASSES[SELECTED_CLASSES[i]]:<15} {baseline_acc:>10.2f}% {poisoned_acc:>10.2f}% {diff:>+10.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate target images with poisoned model\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Evaluating target images with poisoned model:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Attack is successful if target is misclassified as base class\")\n",
        "\n",
        "poisoned_target_predictions, poisoned_target_probs = predict_images(poisoned_model, target_images)\n",
        "\n",
        "successful_attacks = 0\n",
        "attack_results = []\n",
        "\n",
        "for i in range(NUM_TARGETS):\n",
        "    pred_class = poisoned_target_predictions[i]\n",
        "    true_class = TARGET_CLASS\n",
        "    is_success = (pred_class == BASE_CLASS)  # Attack successful if misclassified as base class\n",
        "    successful_attacks += is_success\n",
        "    \n",
        "    pred_class_name = CIFAR10_CLASSES[SELECTED_CLASSES[pred_class]]\n",
        "    true_class_name = CIFAR10_CLASSES[SELECTED_CLASSES[true_class]]\n",
        "    base_class_name = CIFAR10_CLASSES[SELECTED_CLASSES[BASE_CLASS]]\n",
        "    \n",
        "    status = \"✓ SUCCESS\" if is_success else \"✗ FAILED\"\n",
        "    attack_results.append({\n",
        "        'target_idx': i,\n",
        "        'predicted': pred_class,\n",
        "        'predicted_name': pred_class_name,\n",
        "        'true_class': true_class,\n",
        "        'true_class_name': true_class_name,\n",
        "        'success': is_success,\n",
        "        'confidence': poisoned_target_probs[i][pred_class]\n",
        "    })\n",
        "    \n",
        "    print(f\"Target {i}: Predicted={pred_class_name} \"\n",
        "          f\"(True={true_class_name}, Goal={base_class_name}) \"\n",
        "          f\"{status} \"\n",
        "          f\"(Confidence: {poisoned_target_probs[i][pred_class]:.3f})\")\n",
        "\n",
        "attack_success_rate = 100 * successful_attacks / NUM_TARGETS\n",
        "print(f\"\\nAttack Success Rate: {attack_success_rate:.1f}% ({successful_attacks}/{NUM_TARGETS} targets misclassified as base class)\")\n",
        "\n",
        "# Compare before and after\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Target Classification: Before vs After Poisoning\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Target':<8} {'Before':<20} {'After':<20} {'Status':<10}\")\n",
        "print(\"-\" * 60)\n",
        "for i in range(NUM_TARGETS):\n",
        "    before_pred = CIFAR10_CLASSES[SELECTED_CLASSES[target_predictions[i]]]\n",
        "    after_pred = CIFAR10_CLASSES[SELECTED_CLASSES[poisoned_target_predictions[i]]]\n",
        "    status = \"SUCCESS\" if attack_results[i]['success'] else \"FAILED\"\n",
        "    print(f\"{i:<8} {before_pred:<20} {after_pred:<20} {status:<10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Report Results (40 points)\n",
        "\n",
        "Summary of results, visualizations, and analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"6. RESULTS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create comprehensive results summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PERFORMANCE METRICS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n1. Test Set Accuracy:\")\n",
        "print(f\"   Baseline (clean model): {baseline_metrics['test_accuracy']:.2f}%\")\n",
        "print(f\"   Poisoned model:         {poisoned_accuracy:.2f}%\")\n",
        "print(f\"   Change:                 {poisoned_accuracy - baseline_metrics['test_accuracy']:+.2f}%\")\n",
        "\n",
        "print(f\"\\n2. Target Image Classification:\")\n",
        "print(f\"   Before poisoning:      {baseline_metrics['target_accuracy']:.1f}% correctly classified as target class\")\n",
        "print(f\"   After poisoning:        {attack_success_rate:.1f}% misclassified as base class (attack success)\")\n",
        "print(f\"   Successful attacks:     {successful_attacks}/{NUM_TARGETS}\")\n",
        "\n",
        "print(f\"\\n3. Per-Class Test Accuracy:\")\n",
        "print(f\"   {'Class':<15} {'Baseline':<12} {'Poisoned':<12} {'Change':<12}\")\n",
        "print(\"   \" + \"-\" * 50)\n",
        "for i in range(NUM_CLASSES):\n",
        "    baseline_acc = 100 * baseline_metrics['class_correct'][i] / baseline_metrics['class_total'][i] if baseline_metrics['class_total'][i] > 0 else 0\n",
        "    poisoned_acc = 100 * poisoned_class_correct[i] / poisoned_class_total[i] if poisoned_class_total[i] > 0 else 0\n",
        "    diff = poisoned_acc - baseline_acc\n",
        "    print(f\"   {CIFAR10_CLASSES[SELECTED_CLASSES[i]]:<15} {baseline_acc:>10.2f}% {poisoned_acc:>10.2f}% {diff:>+10.2f}%\")\n",
        "\n",
        "# Create visualization of attack results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Accuracy comparison\n",
        "ax1 = axes[0, 0]\n",
        "categories = ['Baseline', 'Poisoned']\n",
        "accuracies = [baseline_metrics['test_accuracy'], poisoned_accuracy]\n",
        "colors = ['blue', 'red']\n",
        "bars = ax1.bar(categories, accuracies, color=colors, alpha=0.7)\n",
        "ax1.set_ylabel('Test Accuracy (%)')\n",
        "ax1.set_title('Overall Test Accuracy: Baseline vs Poisoned')\n",
        "ax1.set_ylim([0, 100])\n",
        "for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
        "             f'{acc:.2f}%', ha='center', va='bottom')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Per-class accuracy comparison\n",
        "ax2 = axes[0, 1]\n",
        "class_names = [CIFAR10_CLASSES[SELECTED_CLASSES[i]] for i in range(NUM_CLASSES)]\n",
        "baseline_class_accs = [100 * baseline_metrics['class_correct'][i] / baseline_metrics['class_total'][i] \n",
        "                       if baseline_metrics['class_total'][i] > 0 else 0 for i in range(NUM_CLASSES)]\n",
        "poisoned_class_accs = [100 * poisoned_class_correct[i] / poisoned_class_total[i] \n",
        "                       if poisoned_class_total[i] > 0 else 0 for i in range(NUM_CLASSES)]\n",
        "\n",
        "x = np.arange(len(class_names))\n",
        "width = 0.35\n",
        "ax2.bar(x - width/2, baseline_class_accs, width, label='Baseline', alpha=0.7, color='blue')\n",
        "ax2.bar(x + width/2, poisoned_class_accs, width, label='Poisoned', alpha=0.7, color='red')\n",
        "ax2.set_xlabel('Class')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('Per-Class Test Accuracy')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(class_names, rotation=45, ha='right')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Target classification results\n",
        "ax3 = axes[1, 0]\n",
        "target_indices = list(range(NUM_TARGETS))\n",
        "before_correct = [1 if target_predictions[i] == TARGET_CLASS else 0 for i in range(NUM_TARGETS)]\n",
        "after_misclassified = [1 if poisoned_target_predictions[i] == BASE_CLASS else 0 for i in range(NUM_TARGETS)]\n",
        "\n",
        "x = np.arange(NUM_TARGETS)\n",
        "width = 0.35\n",
        "ax3.bar(x - width/2, before_correct, width, label='Correctly classified\\n(before)', alpha=0.7, color='green')\n",
        "ax3.bar(x + width/2, after_misclassified, width, label='Misclassified as base\\n(after)', alpha=0.7, color='orange')\n",
        "ax3.set_xlabel('Target Image Index')\n",
        "ax3.set_ylabel('Classification Status')\n",
        "ax3.set_title('Target Image Classification: Before vs After')\n",
        "ax3.set_xticks(x)\n",
        "ax3.set_xticklabels(target_indices)\n",
        "ax3.set_ylim([0, 1.2])\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Attack success visualization\n",
        "ax4 = axes[1, 1]\n",
        "success_count = successful_attacks\n",
        "fail_count = NUM_TARGETS - successful_attacks\n",
        "ax4.pie([success_count, fail_count], labels=[f'Success\\n({success_count})', f'Failed\\n({fail_count})'], \n",
        "        autopct='%1.1f%%', startangle=90, colors=['orange', 'gray'])\n",
        "ax4.set_title(f'Attack Success Rate\\n({successful_attacks}/{NUM_TARGETS} targets)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final poison images grid\n",
        "print(\"\\nFinal Poison Images (all 10):\")\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for i in range(NUM_POISONS):\n",
        "    row = i // 5\n",
        "    col = i % 5\n",
        "    poison_img = denormalize(poisons[i].cpu().clone())\n",
        "    axes[row, col].imshow(poison_img.permute(1, 2, 0))\n",
        "    axes[row, col].set_title(f'Poison {i}\\nLabel: {CIFAR10_CLASSES[SELECTED_CLASSES[BASE_CLASS]]}')\n",
        "    axes[row, col].axis('off')\n",
        "plt.suptitle('All Final Poison Images', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Detailed target analysis\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DETAILED TARGET ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "for i, result in enumerate(attack_results):\n",
        "    print(f\"\\nTarget {i}:\")\n",
        "    print(f\"  True class: {result['true_class_name']}\")\n",
        "    print(f\"  Predicted (before): {CIFAR10_CLASSES[SELECTED_CLASSES[target_predictions[i]]]}\")\n",
        "    print(f\"  Predicted (after):  {result['predicted_name']} (confidence: {result['confidence']:.3f})\")\n",
        "    print(f\"  Attack status: {'SUCCESS ✓' if result['success'] else 'FAILED ✗'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion\n",
        "\n",
        "### Results Analysis\n",
        "\n",
        "The results will show:\n",
        "\n",
        "1. **Attack Effectiveness**: The clean-label poisoning attack attempts to misclassify target images as the base class after retraining. The success rate depends on the optimization convergence and the robustness of the target images.\n",
        "\n",
        "2. **Model Performance**: The overall test accuracy should remain relatively stable, indicating that the poisons do not significantly degrade general model performance while achieving the attack goal.\n",
        "\n",
        "3. **Why Some Attacks Succeeded/Failed**: \n",
        "   - Successful attacks: The poison images successfully learned feature representations similar to their corresponding target images while maintaining the base class label.\n",
        "   - Failed attacks: Some targets may have been more robust to the poisoning attack, or the optimization may not have converged sufficiently for those particular target-base pairs.\n",
        "\n",
        "4. **Poison Characteristics**: The generated poisons are visually similar to the base images but contain subtle perturbations that cause the model to learn features that match the target images in the feature space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a summary table for the report\n",
        "\n",
        "# Summary table\n",
        "summary_data = {\n",
        "    'Metric': [\n",
        "        'Baseline Test Accuracy (%)',\n",
        "        'Poisoned Test Accuracy (%)',\n",
        "        'Accuracy Change (%)',\n",
        "        'Target Classification (Before)',\n",
        "        'Target Classification (After)',\n",
        "        'Attack Success Rate (%)',\n",
        "        'Successful Attacks',\n",
        "        'Total Targets'\n",
        "    ],\n",
        "    'Value': [\n",
        "        f\"{baseline_metrics['test_accuracy']:.2f}\",\n",
        "        f\"{poisoned_accuracy:.2f}\",\n",
        "        f\"{poisoned_accuracy - baseline_metrics['test_accuracy']:+.2f}\",\n",
        "        f\"{baseline_metrics['target_accuracy']:.1f}% correct\",\n",
        "        f\"{attack_success_rate:.1f}% misclassified\",\n",
        "        f\"{attack_success_rate:.1f}\",\n",
        "        f\"{successful_attacks}\",\n",
        "        f\"{NUM_TARGETS}\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXECUTIVE SUMMARY TABLE\")\n",
        "print(\"=\" * 60)\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "# Per-class summary\n",
        "class_summary_data = {\n",
        "    'Class': [CIFAR10_CLASSES[SELECTED_CLASSES[i]] for i in range(NUM_CLASSES)],\n",
        "    'Baseline Accuracy (%)': [\n",
        "        f\"{100 * baseline_metrics['class_correct'][i] / baseline_metrics['class_total'][i]:.2f}\" \n",
        "        if baseline_metrics['class_total'][i] > 0 else \"0.00\" \n",
        "        for i in range(NUM_CLASSES)\n",
        "    ],\n",
        "    'Poisoned Accuracy (%)': [\n",
        "        f\"{100 * poisoned_class_correct[i] / poisoned_class_total[i]:.2f}\" \n",
        "        if poisoned_class_total[i] > 0 else \"0.00\" \n",
        "        for i in range(NUM_CLASSES)\n",
        "    ],\n",
        "    'Change (%)': [\n",
        "        f\"{100 * poisoned_class_correct[i] / poisoned_class_total[i] - 100 * baseline_metrics['class_correct'][i] / baseline_metrics['class_total'][i]:+.2f}\" \n",
        "        if poisoned_class_total[i] > 0 and baseline_metrics['class_total'][i] > 0 else \"0.00\" \n",
        "        for i in range(NUM_CLASSES)\n",
        "    ]\n",
        "}\n",
        "\n",
        "class_summary_df = pd.DataFrame(class_summary_data)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PER-CLASS ACCURACY SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(class_summary_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ASSIGNMENT COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nAll required components have been implemented:\")\n",
        "print(\"✓ Data preparation with 4 classes, targets, and base images\")\n",
        "print(\"✓ Small CNN architecture (3 conv layers + 2 FC layers)\")\n",
        "print(\"✓ Initial training and baseline evaluation\")\n",
        "print(\"✓ Poison generation using iterative optimization\")\n",
        "print(\"✓ Retraining on poisoned data\")\n",
        "print(\"✓ Comprehensive evaluation and visualization\")\n",
        "print(\"✓ Results summary and analysis\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
